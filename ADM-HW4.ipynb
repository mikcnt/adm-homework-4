{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T00:04:06.906056Z",
     "iopub.status.busy": "2020-12-16T00:04:06.905050Z",
     "iopub.status.idle": "2020-12-16T00:04:07.102025Z",
     "shell.execute_reply": "2020-12-16T00:04:07.101536Z",
     "shell.execute_reply.started": "2020-12-16T00:04:06.905885Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequentially adding data to the HLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T00:04:07.102919Z",
     "iopub.status.busy": "2020-12-16T00:04:07.102757Z",
     "iopub.status.idle": "2020-12-16T00:08:25.328912Z",
     "shell.execute_reply": "2020-12-16T00:08:25.328353Z",
     "shell.execute_reply.started": "2020-12-16T00:04:07.102874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 21, 23, 21, 23, 25, 22, 23, 23, 20, 21, 23, 21, 20, 22, 22, 21, 26, 20, 21, 26, 22, 21, 22, 22, 22, 20, 22, 25, 23, 26, 22, 24, 21, 21, 21, 21, 20, 20, 21, 24, 21, 24, 25, 22, 21, 25, 25, 25, 22, 20, 24, 22, 26, 20, 24, 24, 26, 21, 26, 20, 25, 22, 21]\n"
     ]
    }
   ],
   "source": [
    "log2m, bits = 6, 32\n",
    "\n",
    "HLL_6 = HyperLogLog(log2m=log2m, bits=bits)\n",
    "\n",
    "hll_6 = HLL_6.structure('hash.txt')\n",
    "\n",
    "print(hll_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cardinality and (relative) error of the filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T00:08:25.331395Z",
     "iopub.status.busy": "2020-12-16T00:08:25.331264Z",
     "iopub.status.idle": "2020-12-16T00:08:25.335238Z",
     "shell.execute_reply": "2020-12-16T00:08:25.334234Z",
     "shell.execute_reply.started": "2020-12-16T00:08:25.331377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bits: 32\n",
      "Bits for the buckets: 6\n",
      "Estimate: 139604896\n",
      "Error: 0.13\n"
     ]
    }
   ],
   "source": [
    "estimate_6 = HLL_6.cardinality(hll_6)\n",
    "error_6 = HLL_6.error()\n",
    "\n",
    "print('Total bits: {}\\nBits for the buckets: {}'.format(bits, log2m))\n",
    "print('Estimate: {}\\nError: {}'.format(estimate_6, error_6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "Maybe we can do a little bit better by increasing the lenght of the root to 11 bits. This seems to be a good point for the tradeoff between error and efficiency!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T00:08:25.336588Z",
     "iopub.status.busy": "2020-12-16T00:08:25.336398Z",
     "iopub.status.idle": "2020-12-16T00:12:49.590376Z",
     "shell.execute_reply": "2020-12-16T00:12:49.589829Z",
     "shell.execute_reply.started": "2020-12-16T00:08:25.336570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bits: 32\n",
      "Bits for the buckets: 11\n",
      "Estimate: 123189077\n",
      "Error: 0.023\n"
     ]
    }
   ],
   "source": [
    "log2m, bits = 11, 32\n",
    "\n",
    "HLL_11 = HyperLogLog(log2m=log2m, bits=bits)\n",
    "\n",
    "hll_11 = HLL_11.structure('hash.txt')\n",
    "\n",
    "estimate_11 = HLL_11.cardinality(hll_11)\n",
    "\n",
    "error_11 = HLL_11.error()\n",
    "\n",
    "print('Total bits: {}\\nBits for the buckets: {}'.format(bits, log2m))\n",
    "print('Estimate: {}\\nError: {:.3f}'.format(estimate_11, error_11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real error\n",
    "To compute the real error of the algorithm we used, we have to count the exact number of unique elements that appear in the `hash.txt` file. In order to do that, there are severel options. One of those is to use shell commands, and that's what we've chosen to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T10:49:09.911821Z",
     "iopub.status.busy": "2020-12-16T10:49:09.911181Z",
     "iopub.status.idle": "2020-12-16T10:51:33.766042Z",
     "shell.execute_reply": "2020-12-16T10:51:33.765091Z",
     "shell.execute_reply.started": "2020-12-16T10:49:09.911741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125000000\n"
     ]
    }
   ],
   "source": [
    "!sort hash.txt | uniq | wc -l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
